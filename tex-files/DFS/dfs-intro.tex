Catalyst integrates its own Distributed File System (DFS) \cite{DFS} based on the InterPlanetary File System (IPFS) protocol \cite{benet2014ipfs}. DFS, as the name suggests, is a peer to peer file system, where the files contained within are distributed across and accessible to a range of peers. This file system will have no down time nor any single point of failure, meaning that they are persistent in a way that other, centralised file storage technologies are not. \\ % Why is DFS different than IPFS? Why not use IPFS directly? What is different in your implementation?



On the Catalyst network every node holds a DFS module. While all nodes will not hold all of the information stored on the DFS, they will be able to query and retrieve any information on the network. Furthermore, nodes will have the ability to query the existence of a file rather than being forced to download the file in order to check its existence. \\ % What information will the nodes be forced to have? Does every node have its own garbage collection implemented? How will they query the existence of files - is it content addressed? How is it content addressed?

Integrating DFS allows the Catalyst network to remain lean as nodes on the network can choose to store only the data that they choose to hold. Furthermore, it allows the storage of many rich file types in a distributed manner, meaning that they are always accessible with no down time guaranteed. \\ % As long as nodes continue to pin that information, sure. Shouldn't we mention that? Also, you can't ensure the uptime of the internet as a whole, so downtime is still possible.

In this section is a description of the IPFS platform that Catalyst uses, and then how Catalyst integrates this into its ecosystem.